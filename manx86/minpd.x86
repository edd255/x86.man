'\" t
.nh
.TH "X86-MINPD" "7" "May 2019" "TTMO" "Intel x86-64 ISA Manual"
.SH NAME
MINPD - MINIMUM OF PACKED DOUBLE PRECISION FLOATING-POINT VALUES
.TS
allbox;
l l l l l 
l l l l l .
\fBOpcode/Instruction\fP	\fBOp / En\fP	\fB64/32 bit Mode Support\fP	\fBCPUID Feature Flag\fP	\fBDescription\fP
T{
66 0F 5D /r MINPD xmm1, xmm2/m128
T}	A	V/V	SSE2	T{
Return the minimum double precision floating-point values between xmm1 and xmm2/mem
T}
T{
VEX.128.66.0F.WIG 5D /r VMINPD xmm1, xmm2, xmm3/m128
T}	B	V/V	AVX	T{
Return the minimum double precision floating-point values between xmm2 and xmm3/mem.
T}
T{
VEX.256.66.0F.WIG 5D /r VMINPD ymm1, ymm2, ymm3/m256
T}	B	V/V	AVX	T{
Return the minimum packed double precision floating-point values between ymm2 and ymm3/mem.
T}
T{
EVEX.128.66.0F.W1 5D /r VMINPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
T}	C	V/V	AVX512VL AVX512F	T{
Return the minimum packed double precision floating-point values between xmm2 and xmm3/m128/m64bcst and store result in xmm1 subject to writemask k1.
T}
T{
EVEX.256.66.0F.W1 5D /r VMINPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
T}	C	V/V	AVX512VL AVX512F	T{
Return the minimum packed double precision floating-point values between ymm2 and ymm3/m256/m64bcst and store result in ymm1 subject to writemask k1.
T}
T{
EVEX.512.66.0F.W1 5D /r VMINPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{sae}
T}	C	V/V	AVX512F	T{
Return the minimum packed double precision floating-point values between zmm2 and zmm3/m512/m64bcst and store result in zmm1 subject to writemask k1.
T}
.TE

.SH INSTRUCTION OPERAND ENCODING
.TS
allbox;
l l l l l l 
l l l l l l .
\fBOp/En\fP	\fBTuple Type\fP	\fBOperand 1\fP	\fBOperand 2\fP	\fBOperand 3\fP	\fBOperand 4\fP
A	N/A	ModRM:reg (r, w)	ModRM:r/m (r)	N/A	N/A
B	N/A	ModRM:reg (w)	VEX.vvvv (r)	ModRM:r/m (r)	N/A
C	Full	ModRM:reg (w)	EVEX.vvvv (r)	ModRM:r/m (r)	N/A
.TE

.SH DESCRIPTION
Performs a SIMD compare of the packed double precision floating-point
values in the first source operand and the second source operand and
returns the minimum value for each pair of values to the destination
operand.

.PP
If the values being compared are both 0.0s (of either sign), the value
in the second operand (source operand) is returned. If a value in the
second operand is an SNaN, then SNaN is forwarded unchanged to the
destination (that is, a QNaN version of the SNaN is not returned).

.PP
If only one value is a NaN (SNaN or QNaN) for this instruction, the
second operand (source operand), either a NaN or a valid floating-point
value, is written to the result. If instead of this behavior, it is
required that the NaN source operand (from either the first or second
operand) be returned, the action of MINPD can be emulated using a
sequence of instructions, such as, a comparison followed by AND, ANDN,
and OR.

.PP
EVEX encoded versions: The first source operand (the second operand) is
a ZMM/YMM/XMM register. The second source operand can be a ZMM/YMM/XMM
register, a 512/256/128-bit memory location or a 512/256/128-bit vector
broadcasted from a 64-bit memory location. The destination operand is a
ZMM/YMM/XMM register conditionally updated with writemask k1.

.PP
VEX.256 encoded version: The first source operand is a YMM register. The
second source operand can be a YMM register or a 256-bit memory
location. The destination operand is a YMM register. The upper bits
(MAXVL-1:256) of the corresponding ZMM register destination are zeroed.

.PP
VEX.128 encoded version: The first source operand is a XMM register. The
second source operand can be a XMM register or a 128-bit memory
location. The destination operand is a XMM register. The upper bits
(MAXVL-1:128) of the corresponding ZMM register destination are zeroed.

.PP
128-bit Legacy SSE version: The second source can be an XMM register or
an 128-bit memory location. The destination is not distinct from the
first source XMM register and the upper bits (MAXVL-1:128) of the
corresponding ZMM register destination are unmodified.

.SH OPERATION
.EX
MIN(SRC1, SRC2)
{
    IF ((SRC1 = 0.0) and (SRC2 = 0.0)) THEN DEST := SRC2;
        ELSE IF (SRC1 = NaN) THEN DEST := SRC2; FI;
        ELSE IF (SRC2 = NaN) THEN DEST := SRC2; FI;
        ELSE IF (SRC1 < SRC2) THEN DEST := SRC1;
        ELSE DEST := SRC2;
    FI;
}
.EE

.SS VMINPD (EVEX Encoded Version)
.EX
(KL, VL) = (2, 128), (4, 256), (8, 512)
FOR j := 0 TO KL-1
    i := j * 64
    IF k1[j] OR *no writemask*
        THEN
            IF (EVEX.b = 1) AND (SRC2 *is memory*)
                THEN
                    DEST[i+63:i] := MIN(SRC1[i+63:i], SRC2[63:0])
                ELSE
                    DEST[i+63:i] := MIN(SRC1[i+63:i], SRC2[i+63:i])
            FI;
        ELSE
            IF *merging-masking* ; merging-masking
                THEN *DEST[i+63:i] remains unchanged*
                ELSE DEST[i+63:i] := 0
                        ; zeroing-masking
            FI
    FI;
ENDFOR
DEST[MAXVL-1:VL] := 0
.EE

.SS VMINPD (VEX.256 Encoded Version)
.EX
DEST[63:0] := MIN(SRC1[63:0], SRC2[63:0])
DEST[127:64] := MIN(SRC1[127:64], SRC2[127:64])
DEST[191:128] := MIN(SRC1[191:128], SRC2[191:128])
DEST[255:192] := MIN(SRC1[255:192], SRC2[255:192])
.EE

.SS VMINPD (VEX.128 Encoded Version)
.EX
DEST[63:0] := MIN(SRC1[63:0], SRC2[63:0])
DEST[127:64] := MIN(SRC1[127:64], SRC2[127:64])
DEST[MAXVL-1:128] := 0
.EE

.SS MINPD (128-bit Legacy SSE Version)
.EX
DEST[63:0] := MIN(SRC1[63:0], SRC2[63:0])
DEST[127:64] := MIN(SRC1[127:64], SRC2[127:64])
DEST[MAXVL-1:128] (Unmodified)
.EE

.SH INTEL C/C++ COMPILER INTRINSIC EQUIVALENT
.EX
VMINPD __m512d _mm512_min_pd( __m512d a, __m512d b);

VMINPD __m512d _mm512_mask_min_pd(__m512d s, __mmask8 k, __m512d a, __m512d b);

VMINPD __m512d _mm512_maskz_min_pd( __mmask8 k, __m512d a, __m512d b);

VMINPD __m512d _mm512_min_round_pd( __m512d a, __m512d b, int);

VMINPD __m512d _mm512_mask_min_round_pd(__m512d s, __mmask8 k, __m512d a, __m512d b, int);

VMINPD __m512d _mm512_maskz_min_round_pd( __mmask8 k, __m512d a, __m512d b, int);

VMINPD __m256d _mm256_mask_min_pd(__m256d s, __mmask8 k, __m256d a, __m256d b);

VMINPD __m256d _mm256_maskz_min_pd( __mmask8 k, __m256d a, __m256d b);

VMINPD __m128d _mm_mask_min_pd(__m128d s, __mmask8 k, __m128d a, __m128d b);

VMINPD __m128d _mm_maskz_min_pd( __mmask8 k, __m128d a, __m128d b);

VMINPD __m256d _mm256_min_pd (__m256d a, __m256d b);

MINPD __m128d _mm_min_pd (__m128d a, __m128d b);
.EE

.SH SIMD FLOATING-POINT EXCEPTIONS
Invalid (including QNaN Source Operand), Denormal.

.SH OTHER EXCEPTIONS
Non-EVEX-encoded instruction, see Table
2-19, “Type 2 Class Exception Conditions.”

.PP
EVEX-encoded instruction, see Table
2-46, “Type E2 Class Exception Conditions.”

.SH SEE ALSO
x86-manpages(7) for a list of other x86-64 man pages.

.SH COLOPHON
This UNOFFICIAL, mechanically-separated, non-verified reference is
provided for convenience, but it may be
incomplete or
broken in various obvious or non-obvious ways.
Refer to Intel® 64 and IA-32 Architectures Software Developer’s Manual
for anything serious.

.br
This page is generated by scripts; therefore may contain visual or semantical bugs. Please report them (or better, fix them) on https://github.com/ttmo-O/x86-manpages.

.br
MIT licensed by TTMO 2025 (Turkish Unofficial Chamber of Reverse Engineers - https://ttmo.re).
