'\" t
.nh
.TH "X86-PCMPEQB-PCMPEQW-PCMPEQD" "7" "May 2019" "TTMO" "Intel x86-64 ISA Manual"
.SH NAME
PCMPEQB-PCMPEQW-PCMPEQD - COMPARE PACKED DATA FOR EQUAL
.TS
allbox;
l l l l l 
l l l l l .
\fBOpcode/Instruction\fP	\fBOp/ En\fP	\fB64/32 bit Mode Support\fP	\fBCPUID Feature Flag\fP	\fBDescription\fP
T{
NP 0F 74 /r1 PCMPEQB mm, mm/m64
T}	A	V/V	MMX	T{
Compare packed bytes in mm/m64 and mm for equality.
T}
T{
66 0F 74 /r PCMPEQB xmm1, xmm2/m128
T}	A	V/V	SSE2	T{
Compare packed bytes in xmm2/m128 and xmm1 for equality.
T}
T{
NP 0F 75 /r1 PCMPEQW mm, mm/m64
T}	A	V/V	MMX	T{
Compare packed words in mm/m64 and mm for equality.
T}
T{
66 0F 75 /r PCMPEQW xmm1, xmm2/m128
T}	A	V/V	SSE2	T{
Compare packed words in xmm2/m128 and xmm1 for equality.
T}
T{
NP 0F 76 /r1 PCMPEQD mm, mm/m64
T}	A	V/V	MMX	T{
Compare packed doublewords in mm/m64 and mm for equality.
T}
T{
66 0F 76 /r PCMPEQD xmm1, xmm2/m128
T}	A	V/V	SSE2	T{
Compare packed doublewords in xmm2/m128 and xmm1 for equality.
T}
T{
VEX.128.66.0F.WIG 74 /r VPCMPEQB xmm1, xmm2, xmm3/m128
T}	B	V/V	AVX	T{
Compare packed bytes in xmm3/m128 and xmm2 for equality.
T}
T{
VEX.128.66.0F.WIG 75 /r VPCMPEQW xmm1, xmm2, xmm3/m128
T}	B	V/V	AVX	T{
Compare packed words in xmm3/m128 and xmm2 for equality.
T}
T{
VEX.128.66.0F.WIG 76 /r VPCMPEQD xmm1, xmm2, xmm3/m128
T}	B	V/V	AVX	T{
Compare packed doublewords in xmm3/m128 and xmm2 for equality.
T}
T{
VEX.256.66.0F.WIG 74 /r VPCMPEQB ymm1, ymm2, ymm3 /m256
T}	B	V/V	AVX2	T{
Compare packed bytes in ymm3/m256 and ymm2 for equality.
T}
T{
VEX.256.66.0F.WIG 75 /r VPCMPEQW ymm1, ymm2, ymm3 /m256
T}	B	V/V	AVX2	T{
Compare packed words in ymm3/m256 and ymm2 for equality.
T}
T{
VEX.256.66.0F.WIG 76 /r VPCMPEQD ymm1, ymm2, ymm3 /m256
T}	B	V/V	AVX2	T{
Compare packed doublewords in ymm3/m256 and ymm2 for equality.
T}
T{
EVEX.128.66.0F.W0 76 /r VPCMPEQD k1 {k2}, xmm2, xmm3/m128/m32bcst
T}	C	V/V	AVX512VL AVX512F	T{
Compare Equal between int32 vector xmm2 and int32 vector xmm3/m128/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
T}
T{
EVEX.256.66.0F.W0 76 /r VPCMPEQD k1 {k2}, ymm2, ymm3/m256/m32bcst
T}	C	V/V	AVX512VL AVX512F	T{
Compare Equal between int32 vector ymm2 and int32 vector ymm3/m256/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
T}
T{
EVEX.512.66.0F.W0 76 /r VPCMPEQD k1 {k2}, zmm2, zmm3/m512/m32bcst
T}	C	V/V	AVX512F	T{
Compare Equal between int32 vectors in zmm2 and zmm3/m512/m32bcst, and set destination k1 according to the comparison results under writemask k2.
T}
T{
EVEX.128.66.0F.WIG 74 /r VPCMPEQB k1 {k2}, xmm2, xmm3 /m128
T}	D	V/V	AVX512VL AVX512BW	T{
Compare packed bytes in xmm3/m128 and xmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
T}
T{
EVEX.256.66.0F.WIG 74 /r VPCMPEQB k1 {k2}, ymm2, ymm3 /m256
T}	D	V/V	AVX512VL AVX512BW	T{
Compare packed bytes in ymm3/m256 and ymm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
T}
T{
EVEX.512.66.0F.WIG 74 /r VPCMPEQB k1 {k2}, zmm2, zmm3 /m512
T}	D	V/V	AVX512BW	T{
Compare packed bytes in zmm3/m512 and zmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
T}
T{
EVEX.128.66.0F.WIG 75 /r VPCMPEQW k1 {k2}, xmm2, xmm3 /m128
T}	D	V/V	AVX512VL AVX512BW	T{
Compare packed words in xmm3/m128 and xmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
T}
T{
EVEX.256.66.0F.WIG 75 /r VPCMPEQW k1 {k2}, ymm2, ymm3 /m256
T}	D	V/V	AVX512VL AVX512BW	T{
Compare packed words in ymm3/m256 and ymm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
T}
T{
EVEX.512.66.0F.WIG 75 /r VPCMPEQW k1 {k2}, zmm2, zmm3 /m512
T}	D	V/V	AVX512BW	T{
Compare packed words in zmm3/m512 and zmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
T}
.TE

.PP
.RS

.PP
1\&. See note in Section 2.5, “Intel® AVX and Intel® SSE Instruction
Exception Classification,” in the Intel® 64 and IA-32 Architectures
Software Developer’s Manual, Volume 3B.

.RE

.SH INSTRUCTION OPERAND ENCODING
.TS
allbox;
l l l l l l 
l l l l l l .
\fBOp/En\fP	\fBTuple Type\fP	\fBOperand 1\fP	\fBOperand 2\fP	\fBOperand 3\fP	\fBOperand 4\fP
A	N/A	ModRM:reg (r, w)	ModRM:r/m (r)	N/A	N/A
B	N/A	ModRM:reg (w)	VEX.vvvv (r)	ModRM:r/m (r)	N/A
C	Full	ModRM:reg (w)	EVEX.vvvv (r)	ModRM:r/m (r)	N/A
D	Full Mem	ModRM:reg (w)	EVEX.vvvv (r)	ModRM:r/m (r)	N/A
.TE

.SH DESCRIPTION
Performs a SIMD compare for equality of the packed bytes, words, or
doublewords in the destination operand (first operand) and the source
operand (second operand). If a pair of data elements is equal, the
corresponding data element in the destination operand is set to all 1s;
otherwise, it is set to all 0s.

.PP
The (V)PCMPEQB instruction compares the corresponding bytes in the
destination and source operands; the (V)PCMPEQW instruction compares the
corresponding words in the destination and source operands; and the
(V)PCMPEQD instruction compares the corresponding doublewords in the
destination and source operands.

.PP
In 64-bit mode and not encoded with VEX/EVEX, using a REX prefix in the
form of REX.R permits this instruction to access additional registers
(XMM8-XMM15).

.PP
Legacy SSE instructions: The source operand can be an MMX technology
register or a 64-bit memory location. The destination operand can be an
MMX technology register.

.PP
128-bit Legacy SSE version: The second source operand can be an XMM
register or a 128-bit memory location. The first source and destination
operands are XMM registers. Bits (MAXVL-1:128) of the corresponding YMM
destination register remain unchanged.

.PP
VEX.128 encoded version: The second source operand can be an XMM
register or a 128-bit memory location. The first source and destination
operands are XMM registers. Bits (MAXVL-1:128) of the corresponding YMM
register are zeroed.

.PP
VEX.256 encoded version: The first source operand is a YMM register. The
second source operand is a YMM register or a 256-bit memory location.
The destination operand is a YMM register.

.PP
EVEX encoded VPCMPEQD: The first source operand (second operand) is a
ZMM/YMM/XMM register. The second source operand can be a ZMM/YMM/XMM
register, a 512/256/128-bit memory location or a 512/256/128-bit vector
broadcasted from a 32-bit memory location. The destination operand
(first operand) is a mask register updated according to the writemask
k2.

.PP
EVEX encoded VPCMPEQB/W: The first source operand (second operand) is a
ZMM/YMM/XMM register. The second source operand can be a ZMM/YMM/XMM
register, a 512/256/128-bit memory location. The destination operand
(first operand) is a mask register updated according to the writemask
k2.

.SH OPERATION
.SS PCMPEQB (With 64-bit Operands)
.EX
IF DEST[7:0] = SRC[7:0]
    THEN DEST[7:0) := FFH;
    ELSE DEST[7:0] := 0; FI;
(* Continue comparison of 2nd through 7th bytes in DEST and SRC *)
IF DEST[63:56] = SRC[63:56]
    THEN DEST[63:56] := FFH;
    ELSE DEST[63:56] := 0; FI;
.EE

.SS COMPARE_BYTES_EQUAL (SRC1, SRC2)
.EX
    IF SRC1[7:0] = SRC2[7:0]
    THEN DEST[7:0] := FFH;
    ELSE DEST[7:0] := 0; FI;
(* Continue comparison of 2nd through 15th bytes in SRC1 and SRC2 *)
    IF SRC1[127:120] = SRC2[127:120]
    THEN DEST[127:120] := FFH;
    ELSE DEST[127:120] := 0; FI;
.EE

.SS COMPARE_WORDS_EQUAL (SRC1, SRC2)
.EX
    IF SRC1[15:0] = SRC2[15:0]
    THEN DEST[15:0] := FFFFH;
    ELSE DEST[15:0] := 0; FI;
(* Continue comparison of 2nd through 7th 16-bit words in SRC1 and SRC2 *)
    IF SRC1[127:112] = SRC2[127:112]
    THEN DEST[127:112] := FFFFH;
    ELSE DEST[127:112] := 0; FI;
.EE

.SS COMPARE_DWORDS_EQUAL (SRC1, SRC2)
.EX
    IF SRC1[31:0] = SRC2[31:0]
    THEN DEST[31:0] := FFFFFFFFH;
    ELSE DEST[31:0] := 0; FI;
(* Continue comparison of 2nd through 3rd 32-bit dwords in SRC1 and SRC2 *)
    IF SRC1[127:96] = SRC2[127:96]
    THEN DEST[127:96] := FFFFFFFFH;
    ELSE DEST[127:96] := 0; FI;
.EE

.SS PCMPEQB (With 128-bit Operands)
.EX
DEST[127:0] := COMPARE_BYTES_EQUAL(DEST[127:0],SRC[127:0])
DEST[MAXVL-1:128] (Unmodified)
.EE

.SS VPCMPEQB (VEX.128 Encoded Version)
.EX
DEST[127:0] := COMPARE_BYTES_EQUAL(SRC1[127:0],SRC2[127:0])
DEST[MAXVL-1:128] := 0
.EE

.SS VPCMPEQB (VEX.256 Encoded Version)
.EX
DEST[127:0] := COMPARE_BYTES_EQUAL(SRC1[127:0],SRC2[127:0])
DEST[255:128] := COMPARE_BYTES_EQUAL(SRC1[255:128],SRC2[255:128])
DEST[MAXVL-1:256] := 0
.EE

.SS VPCMPEQB (EVEX Encoded Versions)
.EX
(KL, VL) = (16, 128), (32, 256), (64, 512)
FOR j := 0 TO KL-1
    i := j * 8
    IF k2[j] OR *no writemask*
        THEN
            /* signed comparison */
            CMP := SRC1[i+7:i] == SRC2[i+7:i];
            IF CMP = TRUE
                THEN DEST[j] := 1;
                ELSE DEST[j] := 0; FI;
        ELSE DEST[j] := 0
                    ; zeroing-masking onlyFI;
    FI;
ENDFOR
DEST[MAX_KL-1:KL] := 0
.EE

.SS PCMPEQW (With 64-bit Operands)
.EX
IF DEST[15:0] = SRC[15:0]
    THEN DEST[15:0] := FFFFH;
    ELSE DEST[15:0] := 0; FI;
(* Continue comparison of 2nd and 3rd words in DEST and SRC *)
IF DEST[63:48] = SRC[63:48]
    THEN DEST[63:48] := FFFFH;
    ELSE DEST[63:48] := 0; FI;
.EE

.SS PCMPEQW (With 128-bit Operands)
.EX
DEST[127:0] := COMPARE_WORDS_EQUAL(DEST[127:0],SRC[127:0])
DEST[MAXVL-1:128] (Unmodified)
.EE

.SS VPCMPEQW (VEX.128 Encoded Version)
.EX
DEST[127:0] := COMPARE_WORDS_EQUAL(SRC1[127:0],SRC2[127:0])
DEST[MAXVL-1:128] := 0
.EE

.SS VPCMPEQW (VEX.256 Encoded Version)
.EX
DEST[127:0] := COMPARE_WORDS_EQUAL(SRC1[127:0],SRC2[127:0])
DEST[255:128] := COMPARE_WORDS_EQUAL(SRC1[255:128],SRC2[255:128])
DEST[MAXVL-1:256] := 0
.EE

.SS VPCMPEQW (EVEX Encoded Versions)
.EX
(KL, VL) = (8, 128), (16, 256), (32, 512)
FOR j := 0 TO KL-1
    i := j * 16
    IF k2[j] OR *no writemask*
        THEN
            /* signed comparison */
            CMP := SRC1[i+15:i] == SRC2[i+15:i];
            IF CMP = TRUE
                THEN DEST[j] := 1;
                ELSE DEST[j] := 0; FI;
        ELSE DEST[j] := 0
                    ; zeroing-masking onlyFI;
    FI;
ENDFOR
DEST[MAX_KL-1:KL] := 0
.EE

.SS PCMPEQD (With 64-bit Operands)
.EX
IF DEST[31:0] = SRC[31:0]
    THEN DEST[31:0] := FFFFFFFFH;
    ELSE DEST[31:0] := 0; FI;
IF DEST[63:32] = SRC[63:32]
    THEN DEST[63:32] := FFFFFFFFH;
    ELSE DEST[63:32] := 0; FI;
.EE

.SS PCMPEQD (With 128-bit Operands)
.EX
DEST[127:0] := COMPARE_DWORDS_EQUAL(DEST[127:0],SRC[127:0])
DEST[MAXVL-1:128] (Unmodified)
.EE

.SS VPCMPEQD (VEX.128 Encoded Version)
.EX
DEST[127:0] := COMPARE_DWORDS_EQUAL(SRC1[127:0],SRC2[127:0])
DEST[MAXVL-1:128] := 0
.EE

.SS VPCMPEQD (VEX.256 Encoded Version)
.EX
DEST[127:0] := COMPARE_DWORDS_EQUAL(SRC1[127:0],SRC2[127:0])
DEST[255:128] := COMPARE_DWORDS_EQUAL(SRC1[255:128],SRC2[255:128])
DEST[MAXVL-1:256] := 0
.EE

.SS VPCMPEQD (EVEX Encoded Versions)
.EX
(KL, VL) = (4, 128), (8, 256), (16, 512)
FOR j := 0 TO KL-1
    i := j * 32
    IF k2[j] OR *no writemask*
        THEN
            /* signed comparison */
            IF (EVEX.b = 1) AND (SRC2 *is memory*)
                THEN CMP := SRC1[i+31:i] = SRC2[31:0];
                ELSE CMP := SRC1[i+31:i] = SRC2[i+31:i];
            FI;
            IF CMP = TRUE
                THEN DEST[j] := 1;
                ELSE DEST[j] := 0; FI;
        ELSE DEST[j] := 0
                    ; zeroing-masking only
    FI;
ENDFOR
DEST[MAX_KL-1:KL] := 0
.EE

.SH INTEL C/C++ COMPILER INTRINSIC EQUIVALENTS
.EX
VPCMPEQB __mmask64 _mm512_cmpeq_epi8_mask(__m512i a, __m512i b);

VPCMPEQB __mmask64 _mm512_mask_cmpeq_epi8_mask(__mmask64 k, __m512i a, __m512i b);

VPCMPEQB __mmask32 _mm256_cmpeq_epi8_mask(__m256i a, __m256i b);

VPCMPEQB __mmask32 _mm256_mask_cmpeq_epi8_mask(__mmask32 k, __m256i a, __m256i b);

VPCMPEQB __mmask16 _mm_cmpeq_epi8_mask(__m128i a, __m128i b);

VPCMPEQB __mmask16 _mm_mask_cmpeq_epi8_mask(__mmask16 k, __m128i a, __m128i b);

VPCMPEQW __mmask32 _mm512_cmpeq_epi16_mask(__m512i a, __m512i b);

VPCMPEQW __mmask32 _mm512_mask_cmpeq_epi16_mask(__mmask32 k, __m512i a, __m512i b);

VPCMPEQW __mmask16 _mm256_cmpeq_epi16_mask(__m256i a, __m256i b);

VPCMPEQW __mmask16 _mm256_mask_cmpeq_epi16_mask(__mmask16 k, __m256i a, __m256i b);

VPCMPEQW __mmask8 _mm_cmpeq_epi16_mask(__m128i a, __m128i b);

VPCMPEQW __mmask8 _mm_mask_cmpeq_epi16_mask(__mmask8 k, __m128i a, __m128i b);

VPCMPEQD __mmask16 _mm512_cmpeq_epi32_mask( __m512i a, __m512i b);

VPCMPEQD __mmask16 _mm512_mask_cmpeq_epi32_mask(__mmask16 k, __m512i a, __m512i b);

VPCMPEQD __mmask8 _mm256_cmpeq_epi32_mask(__m256i a, __m256i b);

VPCMPEQD __mmask8 _mm256_mask_cmpeq_epi32_mask(__mmask8 k, __m256i a, __m256i b);

VPCMPEQD __mmask8 _mm_cmpeq_epi32_mask(__m128i a, __m128i b);

VPCMPEQD __mmask8 _mm_mask_cmpeq_epi32_mask(__mmask8 k, __m128i a, __m128i b);

PCMPEQB __m64 _mm_cmpeq_pi8 (__m64 m1, __m64 m2)

PCMPEQW __m64 _mm_cmpeq_pi16 (__m64 m1, __m64 m2)

PCMPEQD __m64 _mm_cmpeq_pi32 (__m64 m1, __m64 m2)

(V)PCMPEQB __m128i _mm_cmpeq_epi8 ( __m128i a, __m128i b)

(V)PCMPEQW __m128i _mm_cmpeq_epi16 ( __m128i a, __m128i b)

(V)PCMPEQD __m128i _mm_cmpeq_epi32 ( __m128i a, __m128i b)

VPCMPEQB __m256i _mm256_cmpeq_epi8 ( __m256i a, __m256i b)

VPCMPEQW __m256i _mm256_cmpeq_epi16 ( __m256i a, __m256i b)

VPCMPEQD __m256i _mm256_cmpeq_epi32 ( __m256i a, __m256i b)
.EE

.SH FLAGS AFFECTED
None.

.SH SIMD FLOATING-POINT EXCEPTIONS
None.

.SH OTHER EXCEPTIONS
Non-EVEX-encoded instruction, see Table
2-21, “Type 4 Class Exception Conditions.”

.PP
EVEX-encoded VPCMPEQD, see Table 2-49,
“Type E4 Class Exception Conditions.”

.PP
EVEX-encoded VPCMPEQB/W, see Exceptions Type E4.nb in
Table 2-49, “Type E4 Class Exception
Conditions.”

.SH SEE ALSO
x86-manpages(7) for a list of other x86-64 man pages.

.SH COLOPHON
This UNOFFICIAL, mechanically-separated, non-verified reference is
provided for convenience, but it may be
incomplete or
broken in various obvious or non-obvious ways.
Refer to Intel® 64 and IA-32 Architectures Software Developer’s Manual
for anything serious.

.br
This page is generated by scripts; therefore may contain visual or semantical bugs. Please report them (or better, fix them) on https://github.com/ttmo-O/x86-manpages.

.br
MIT licensed by TTMO 2025 (Turkish Unofficial Chamber of Reverse Engineers - https://ttmo.re).
