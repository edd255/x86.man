'\" t
.nh
.TH "X86-VGETMANTPD" "7" "May 2019" "TTMO" "Intel x86-64 ISA Manual"
.SH NAME
VGETMANTPD - EXTRACT FLOAT64 VECTOR OF NORMALIZED MANTISSAS FROM FLOAT64 VECTOR
.TS
allbox;
l l l l l 
l l l l l .
\fBOpcode/Instruction\fP	\fBOp/En\fP	\fB64/32 Bit Mode Support\fP	\fBCPUID Feature Flag\fP	\fBDescription\fP
T{
EVEX.128.66.0F3A.W1 26 /r ib VGETMANTPD xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8
T}	A	V/V	AVX512VL AVX512F	T{
Get Normalized Mantissa from float64 vector xmm2/m128/m64bcst and store the result in xmm1, using imm8 for sign control and mantissa interval normalization, under writemask.
T}
T{
EVEX.256.66.0F3A.W1 26 /r ib VGETMANTPD ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8
T}	A	V/V	AVX512VL AVX512F	T{
Get Normalized Mantissa from float64 vector ymm2/m256/m64bcst and store the result in ymm1, using imm8 for sign control and mantissa interval normalization, under writemask.
T}
T{
EVEX.512.66.0F3A.W1 26 /r ib VGETMANTPD zmm1 {k1}{z}, zmm2/m512/m64bcst{sae}, imm8
T}	A	V/V	AVX512F	T{
Get Normalized Mantissa from float64 vector zmm2/m512/m64bcst and store the result in zmm1, using imm8 for sign control and mantissa interval normalization, under writemask.
T}
.TE

.SH INSTRUCTION OPERAND ENCODING
.TS
allbox;
l l l l l l 
l l l l l l .
\fBOp/En\fP	\fBTuple Type\fP	\fBOperand 1\fP	\fBOperand 2\fP	\fBOperand 3\fP	\fBOperand 4\fP
A	Full	ModRM:reg (w)	ModRM:r/m (r)	imm8	N/A
.TE

.SS Description
Convert double precision floating values in the source operand (the
second operand) to double precision floating-point values with the
mantissa normalization and sign control specified by the imm8 byte, see
Figure 5-15. The converted results are written to the destination
operand (the first operand) using writemask k1. The normalized mantissa
is specified by interv (imm8[1:0]) and the sign control (sc) is
specified by bits 3:2 of the immediate byte.

.PP
The destination operand is a ZMM/YMM/XMM register updated under the
writemask. The source operand can be a ZMM/YMM/XMM register, a
512/256/128-bit memory location, or a 512/256/128-bit vector broadcasted
from a 64-bit memory location.

.PP
For each input double precision floating-point value x, The conversion
operation is:

.PP
GetMant(x) = ±2k|x.significand|

.PP
where:

.PP
1 &lt;= |x.significand| &lt; 2

.PP
Unbiased exponent k can be either 0 or -1, depending on the interval
range defined by interv, the range of the significand and whether the
exponent of the source is even or odd. The sign of the final result is
determined by sc

.PP
and the source sign. The encoded value of imm8[1:0] and sign control
are shown in Figure 5-15.

.PP
Each converted double precision floating-point result is encoded
according to the sign control, the unbiased exponent k (adding bias) and
a mantissa normalized to the range specified by interv.

.PP
The GetMant() function follows Table 5-18 when dealing with
floating-point special numbers.

.PP
This instruction is writemasked, so only those elements with the
corresponding bit set in vector mask register k1 are computed and stored
into the destination. Elements in zmm1 with the corresponding bit clear
in k1 retain their previous values.

.PP
Note: EVEX.vvvv is reserved and must be 1111b; otherwise instructions
will #UD.

.PP
.RS

.PP
1\&. In case SC[1]==0, the sign of Getmant(SRC) is declared according
to SC[0]\&.

.RE

.SS Operation
.EX
def getmant_fp64(src, sign_control, normalization_interval):
    bias := 1023
    dst.sign := sign_control[0] ? 0 : src.sign
    signed_one := sign_control[0] ? +1.0 : -1.0
    dst.exp := src.exp
    dst.fraction := src.fraction
    zero := (dst.exp = 0) and ((dst.fraction = 0) or (MXCSR.DAZ=1))
    denormal := (dst.exp = 0) and (dst.fraction != 0) and (MXCSR.DAZ=0)
    infinity := (dst.exp = 0x7FF) and (dst.fraction = 0)
    nan := (dst.exp = 0x7FF) and (dst.fraction != 0)
    src_signaling := src.fraction[51]
    snan := nan and (src_signaling = 0)
    positive := (src.sign = 0)
    negative := (src.sign = 1)
    if nan:
        if snan:
            MXCSR.IE := 1
        return qnan(src)
    if positive and (zero or infinity):
        return 1.0
    if negative:
        if zero:
            return signed_one
        if infinity:
            if sign_control[1]:
                MXCSR.IE := 1
                return QNaN_Indefinite
            return signed_one
        if sign_control[1]:
            MXCSR.IE := 1
            return QNaN_Indefinite
    if denormal:
        jbit := 0
        dst.exp := bias
        while jbit = 0:
            jbit := dst.fraction[51]
            dst.fraction := dst.fraction << 1
            dst.exp : = dst.exp - 1
        MXCSR.DE := 1
    unbiased_exp := dst.exp - bias
    odd_exp := unbiased_exp[0]
    signaling_bit := dst.fraction[51]
    if normalization_interval = 0b00:
        dst.exp := bias
    else if normalization_interval = 0b01:
        dst.exp := odd_exp ? bias-1 : bias
    else if normalization_interval = 0b10:
        dst.exp := bias-1
    else if normalization_interval = 0b11:
        dst.exp := signaling_bit ? bias-1 : bias
    return dst
.EE

.SS VGETMANTPD (EVEX Encoded Versions)
.EX
VGETMANTPD dest{k1}, src, imm8
VL = 128, 256, or 512
KL := VL / 64
sign_control := imm8[3:2]
normalization_interval := imm8[1:0]
FOR i := 0 to KL-1:
    IF k1[i] or *no writemask*:
        IF SRC is memory and (EVEX.b = 1):
            tsrc := src.double[0]
        ELSE:
            tsrc := src.double[i]
        DEST.double[i] := getmant_fp64(tsrc, sign_control, normalization_interval)
    ELSE IF *zeroing*:
        DEST.double[i] := 0
    //else DEST.double[i] remains unchanged
DEST[MAX_VL-1:VL] := 0
.EE

.SS Intel C/C++ Compiler Intrinsic Equivalent
.EX
VGETMANTPD __m512d _mm512_getmant_pd( __m512d a, enum intv, enum sgn);

VGETMANTPD __m512d _mm512_mask_getmant_pd(__m512d s, __mmask8 k, __m512d a, enum intv, enum sgn);

VGETMANTPD __m512d _mm512_maskz_getmant_pd( __mmask8 k, __m512d a, enum intv, enum sgn);

VGETMANTPD __m512d _mm512_getmant_round_pd( __m512d a, enum intv, enum sgn, int r);

VGETMANTPD __m512d _mm512_mask_getmant_round_pd(__m512d s, __mmask8 k, __m512d a, enum intv, enum sgn, int r);

VGETMANTPD __m512d _mm512_maskz_getmant_round_pd( __mmask8 k, __m512d a, enum intv, enum sgn, int r);

VGETMANTPD __m256d _mm256_getmant_pd( __m256d a, enum intv, enum sgn);

VGETMANTPD __m256d _mm256_mask_getmant_pd(__m256d s, __mmask8 k, __m256d a, enum intv, enum sgn);

VGETMANTPD __m256d _mm256_maskz_getmant_pd( __mmask8 k, __m256d a, enum intv, enum sgn);

VGETMANTPD __m128d _mm_getmant_pd( __m128d a, enum intv, enum sgn);

VGETMANTPD __m128d _mm_mask_getmant_pd(__m128d s, __mmask8 k, __m128d a, enum intv, enum sgn);

VGETMANTPD __m128d _mm_maskz_getmant_pd( __mmask8 k, __m128d a, enum intv, enum sgn);
.EE

.SS SIMD Floating-Point Exceptions
Denormal, Invalid.

.SS Other Exceptions
See Table 2-46, “Type E2 Class
Exception Conditions.”

.PP
Additionally:

.TS
allbox;
l l 
l l .
\fB\fP	\fB\fP
#UD	If EVEX.vvvv != 1111B.
.TE

.SH SEE ALSO
x86-manpages(7) for a list of other x86-64 man pages.

.SH COLOPHON
This UNOFFICIAL, mechanically-separated, non-verified reference is
provided for convenience, but it may be
incomplete or
broken in various obvious or non-obvious ways.
Refer to Intel® 64 and IA-32 Architectures Software Developer’s Manual
for anything serious.

.br
This page is generated by scripts; therefore may contain visual or semantical bugs. Please report them (or better, fix them) on https://github.com/ttmo-O/x86-manpages.

.br
MIT licensed by TTMO 2025 (Turkish Unofficial Chamber of Reverse Engineers - https://ttmo.re).
